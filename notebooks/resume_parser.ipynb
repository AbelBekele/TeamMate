{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Affinda for resume parsing - 50 free documents on free trial\n",
    "#Documentation: https://api.affinda.com/docs#post-/v2/resumes\n",
    "#Request free trial: https://www.affinda.com/resume-parser\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from affinda import AffindaAPI, TokenCredential\n",
    "from affinda.models import WorkspaceCreate, CollectionCreate\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Access a value; replace 'YOUR_VARIABLE' with your actual variable name\n",
    "token = os.getenv('AFFINDA_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResumeParser:\n",
    "    def __init__(self):\n",
    "        # Access a value; replace 'YOUR_VARIABLE' with your actual variable name\n",
    "        token = os.getenv('AFFINDA_TOKEN')\n",
    "        self.client = AffindaAPI(credential=TokenCredential(token=token))\n",
    "\n",
    "    def parse_pdf(self, pdf_file_path):\n",
    "        #\n",
    "\n",
    "        # First get the organisation, by default your first one will have free credits\n",
    "        my_organisation = self.client.get_all_organizations()[0]\n",
    "        workspace = self.client.get_all_workspaces(my_organisation.identifier)[0]\n",
    "        collection = self.client.get_all_collections(workspace.identifier)[0]\n",
    "\n",
    "        # # And within that organisation, create a workspace, for example for Recruitment:\n",
    "        # workspace_body = WorkspaceCreate(\n",
    "        #     organization=my_organisation.identifier,\n",
    "        #     name=\"My Workspace\",\n",
    "        # )\n",
    "        # recruitment_workspace = self.client.create_workspace(body=workspace_body)\n",
    "\n",
    "        # # Finally, create a collection that will contain our uploaded documents, for example resumes, by selecting the\n",
    "        # # appropriate extractor\n",
    "        # collection_body = CollectionCreate(\n",
    "        #     name=\"Resumes\", workspace=recruitment_workspace.identifier, extractor=\"resume\"\n",
    "        # )\n",
    "        # resume_collection = self.client.create_collection(collection_body)\n",
    "\n",
    "        # Create resume with file\n",
    "        file_pth = Path(pdf_file_path)\n",
    "\n",
    "        with open(file_pth, \"rb\") as f:\n",
    "            resume = self.client.create_document(file=f, collection=collection.identifier)\n",
    "\n",
    "        return resume.as_dict()\n",
    "\n",
    "    def format_resume(self, resume_dict):\n",
    "        #Takes the output from Affinda and formats to a format that we need\n",
    "        parsed = {}\n",
    "        parsed['name'] = resume_dict['data']['name']['raw']\n",
    "        parsed['total_years_experience'] = resume_dict['data']['total_years_experience']\n",
    "        parsed['education'] = []\n",
    "        for e in resume_dict['data']['education']:\n",
    "            education_dict = {}\n",
    "            education_dict['organization'] = e.get('organization', '')\n",
    "            education_dict['degree'] = e['accreditation']['input_str']\n",
    "            parsed['education'].append(education_dict)\n",
    "\n",
    "        parsed['work'] = []\n",
    "        for w in resume_dict['data']['work_experience']:\n",
    "            work_dict = {}\n",
    "            work_dict['company'] = w.get('organization', '')\n",
    "            work_dict['title'] = w.get('job_title', '')\n",
    "            work_dict['job_description'] = w.get('job_description', '')\n",
    "            parsed['work'].append(work_dict)\n",
    "\n",
    "        parsed['skills'] = []\n",
    "        for s in resume_dict['data']['skills']:\n",
    "            parsed['skills'].append(s['name'])\n",
    "\n",
    "        return parsed\n",
    "    \n",
    "    def construct_embed_string(self, pdf_file_path):\n",
    "        formatted = self.format_resume(self.parse_pdf(pdf_file_path))\n",
    "        embed_string = ''\n",
    "        embed_string += f\"The candidate's name is {formatted['name']}, and he has a total of {formatted['total_years_experience']} years of experience \\n\"\n",
    "        for e in formatted['education']:\n",
    "            embed_string += f\"The candidate has a degree in {e['degree']} from {e.get('organization', '')}\\n\"\n",
    "        \n",
    "        embed_string += '\\n\\n'\n",
    "        for w in formatted['work']:\n",
    "            embed_string += \"The candidate worked at \"\n",
    "            embed_string += f\"{w['company']} as a {w['title']}. Responsibilities included \\n\"\n",
    "            for jr in w['job_description'].split('\\n'):\n",
    "                embed_string += jr + '\\n'\n",
    "            embed_string += '\\n \\n'\n",
    "        \n",
    "        embed_string += '\\n\\n'\n",
    "        embed_string += 'The candidate is skilled in the following \\n'\n",
    "        for s in formatted['skills']:\n",
    "            embed_string += s + '\\n'\n",
    "        \n",
    "        return embed_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The candidate's name is Abel Bekele, and he has a total of 3 years of experience \n",
      "The candidate has a degree in Generative AI from 10 Academy\n",
      "The candidate has a degree in Software Engineering from ALX Africa\n",
      "The candidate has a degree in Mechatronics Engineering from Hawassa University\n",
      "\n",
      "\n",
      "The candidate worked at Tsiune Technologies as a MLOps Engineer. Responsibilities included \n",
      "• Improved tender file processing efficiency by 30%, reducing manual effort from 20 hours to 14 hours per week, by implementing a RAG system that extracts requirements, enables deadline tracking and highlights special attention items. \n",
      "• Enhanced model accuracy from 80% to 96% and reduced time-to-market from8weeks to 6 weeks through proactive monitoring, seamless integration of ML models into web apps, and streamlining ML pipelines with automated deployments. \n",
      "• Boosted customer engagement by 25% by successfully integrating ML models into web applications, providing a more personalized and interactive user experience. \n",
      "\n",
      " \n",
      "The candidate worked at RDX Delta Rabbit Technologies as a Full Stack Engineer. Responsibilities included \n",
      "• Designed and implemented a scalable education web app as a backend engineer, creating robust infrastructure, efficient APIs, and optimizing performance and security, resulting in a seamless online learning and collaboration platform. \n",
      "• Developed and deployed a secure work management tool on AWS, increasing efficiency by 40% and streamlining access to confidential work files for 80 authorized users, ensuring data protection and ease of access. \n",
      "• Mentored junior developers, providing technical guidance and support, resulting in a 20% improvement in team productivity and fostering professional growth. \n",
      "\n",
      " \n",
      "The candidate worked at MKTY IT Services as a Software Engineer. Responsibilities included \n",
      "• Integrated open-source ERP with time attendance machine using MySQL at Grand Palace Administrations of Ethiopia, enhancing workforce management efficiency by 30% for 200 employees and streamlining attendance tracking processes, reducing manual errors by 5%. \n",
      "• Designed, implemented, and launched a comprehensive network infrastructure for a multi-purpose mall using advanced software technologies, improving connectivity and user experience by 25%, leading to increased customer satisfaction & retention. \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "The candidate is skilled in the following \n",
      "Image Generation\n",
      "Amazon Web Services\n",
      "Computer Vision\n",
      "Calculus\n",
      "Streamlining\n",
      "Embedding\n",
      "Collaboration\n",
      "Contract Management\n",
      "Web Applications\n",
      "Workforce Management\n",
      "Network Infrastructure\n",
      "Management\n",
      "MFG/Pro (ERP)\n",
      "Engineering Statistics\n",
      "Python (Programming Language)\n",
      "MySQL\n",
      "Customer Satisfaction\n",
      "SQL (Programming Language)\n",
      "Integration\n",
      "Infrastructure\n",
      "Flask (Web Framework)\n",
      "Tokenization\n",
      "Linear Algebra\n",
      "Algebra\n",
      "Natural Language Processing\n",
      "User Experience\n",
      "TensorFlow\n",
      "Statistics\n",
      "PostgreSQL\n",
      "Indexing\n",
      "Object-Oriented Programming (OOP)\n",
      "Chunking\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__=='__main__':\n",
    "    rs = ResumeParser()\n",
    "    es = rs.construct_embed_string(\"AbelBekele-CV_AI.pdf\")\n",
    "    print(es)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
